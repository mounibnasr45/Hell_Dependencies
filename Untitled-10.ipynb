{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0404c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Optional, Set, FrozenSet, Any\n",
    "from dataclasses import dataclass, field\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "import json # For potential caching or structured errors later\n",
    "\n",
    "try:\n",
    "    from packaging.specifiers import SpecifierSet, InvalidSpecifier\n",
    "    from packaging.version import Version, InvalidVersion\n",
    "    PACKAGING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PACKAGING_AVAILABLE = False\n",
    "    print(\"CRITICAL WARNING: 'packaging' library not found. Please install it: pip install packaging\")\n",
    "    # Dummy classes if 'packaging' is not available\n",
    "    class Version: \n",
    "        def __init__(self, v_str): self.v_str = str(v_str); self.major=0;self.minor=0;self.micro=0 # Simplified\n",
    "        def __str__(self): return self.v_str\n",
    "        def __lt__(self, other): return self.v_str < other.v_str # Naive comparison\n",
    "        def __eq__(self, other): return self.v_str == other.v_str\n",
    "        def __hash__(self): return hash(self.v_str)\n",
    "\n",
    "    class SpecifierSet: \n",
    "        def __init__(self, s_str): self.s_str = str(s_str)\n",
    "        def __contains__(self, version_obj: Version): # Naive check\n",
    "            if self.s_str.startswith(\"==\"): return version_obj.v_str == self.s_str[2:]\n",
    "            return True # Overly permissive for dummy\n",
    "        def __str__(self): return self.s_str\n",
    "    class InvalidSpecifier(Exception): pass\n",
    "    class InvalidVersion(Exception): pass\n",
    "\n",
    "\n",
    "# --- Global Cache for pip-compile results (for V3) ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05311dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script (Optimized V3) is running under Python interpreter: c:\\Users\\mouni\\anaconda3\\python.exe\n",
      "pip-compile command found. Version: pip-compile.EXE, version 7.4.1\n",
      "\n",
      "\n",
      "===== Running Test Case:  Sphinx and Docutils Compatibility =====\n",
      "Initial requirements:\n",
      "requests==2.25.1\n",
      "urllib3==2.0.0\n",
      "\n",
      "Starting A* search. Max iterations: 30. Python: c:\\Users\\mouni\\anaconda3\\python.exe\n",
      "\n",
      ">>> SUCCESS: Solution Found after 5 iterations! <<<\n",
      "\n",
      "--- Final Solution Found ---\n",
      "Solved Requirements:\n",
      "  requests==2.31.0\n",
      "  urllib3==2.0.0\n",
      "\n",
      "Path to solution (Actions taken):\n",
      "  Step 0: Initial state -> Reqs: requests==2.25.1, urllib3==2.0.0\n",
      "  Step 1: Changed requests from '==2.25.1' to '==2.31.0' -> Reqs: requests==2.31.0, urllib3==2.0.0\n",
      "\n",
      "Total time for  Sphinx and Docutils Compatibility: 23.441 seconds\n",
      "Cache size for  Sphinx and Docutils Compatibility: 5 entries.\n",
      "=========================================\n",
      "\n",
      "\n",
      "===== Running Manual Debug Test Case =====\n",
      "Initial requirements:\n",
      "tensorflow==2.8.0\n",
      "pandas==1.4.4\n",
      "some-ml-tool==1.0\n",
      "\n",
      "Parsing initial requirements...\n",
      "Initial direct requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "Performing initial pip-compile run for start_node...\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_aok1h95e\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_aok1h95e\\requirements.in\n",
      "    pip-compile timed out\n",
      "Starting A* search. Max iterations: 15. Python: c:\\Users\\mouni\\anaconda3\\python.exe\n",
      "Initial node: f=3.00 (g=0, h=3.00), reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "  Initial conflict involves: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "\n",
      "--- Iteration 1/15 ---\n",
      "  Expanding node: f=3.00 (g=0.00, h=3.00)\n",
      "  Action leading to this node: 'Initial state'\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "  [Cache] Hit for: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.8.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.8.0', '2.6.0']...\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.8.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.8.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.8.0' to '==2.9.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.8.0' to '==2.6.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.8.0' to '==2.5.0', cost=2.00\n",
      "    Added neighbor to OPEN: f=5.00, g=2.00, h=3.00 | Action: 'Changed tensorflow from '==2.8.0' to '==2.13.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Added neighbor to OPEN: f=5.00, g=2.00, h=3.00 | Action: 'Changed tensorflow from '==2.8.0' to '==2.10.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Added neighbor to OPEN: f=5.00, g=2.00, h=3.00 | Action: 'Changed tensorflow from '==2.8.0' to '==2.9.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Added neighbor to OPEN: f=5.00, g=2.00, h=3.00 | Action: 'Changed tensorflow from '==2.8.0' to '==2.6.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "    Added neighbor to OPEN: f=5.00, g=2.00, h=3.00 | Action: 'Changed tensorflow from '==2.8.0' to '==2.5.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "\n",
      "--- Iteration 2/15 ---\n",
      "  Expanding node: f=5.00 (g=2.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.8.0' to '==2.13.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_wnnp91h9\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_wnnp91h9\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.13.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0']\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.13.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.13.0' to '==2.9.0', cost=2.00\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.13.0' to '==2.10.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.13.0' to '==2.9.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "\n",
      "--- Iteration 3/15 ---\n",
      "  Expanding node: f=5.00 (g=2.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.8.0' to '==2.9.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_euhxdpc8\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_euhxdpc8\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.9.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.8.0', '2.6.0']\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.9.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.9.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.9.0' to '==2.8.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.9.0' to '==2.6.0', cost=2.00\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.9.0' to '==2.10.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.9.0' to '==2.6.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "\n",
      "--- Iteration 4/15 ---\n",
      "  Expanding node: f=5.00 (g=2.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.8.0' to '==2.5.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_pfgd3y1c\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_pfgd3y1c\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.5.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.8.0', '2.6.0']...\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.9.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.8.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.6.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.5.0' to '==2.3.0', cost=2.00\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.5.0' to '==2.10.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.5.0' to '==2.6.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.5.0' to '==2.3.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "\n",
      "--- Iteration 5/15 ---\n",
      "  Expanding node: f=5.00 (g=2.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.8.0' to '==2.10.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_wt3j7ws2\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_wt3j7ws2\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.10.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.8.0']\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.10.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.10.0' to '==2.9.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.10.0' to '==2.8.0', cost=2.00\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "\n",
      "--- Iteration 6/15 ---\n",
      "  Expanding node: f=5.00 (g=2.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.8.0' to '==2.6.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_hq1yqnto\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_hq1yqnto\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.6.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.8.0', '2.6.0']...\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.9.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.8.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.5.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.6.0' to '==2.3.0', cost=2.00\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.8.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "    Added neighbor to OPEN: f=7.00, g=4.00, h=3.00 | Action: 'Changed tensorflow from '==2.6.0' to '==2.3.0'' | Reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "\n",
      "--- Iteration 7/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.13.0' to '==2.9.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 8/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.5.0' to '==2.10.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 9/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.5.0' to '==2.6.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 10/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.9.0' to '==2.10.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 11/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.6.0' to '==2.3.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "  [Resolver] Attempting to resolve: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "    Executing: C:\\Users\\mouni\\anaconda3\\Scripts\\pip-compile.EXE --resolver=backtracking --verbose --output-file C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_gpapqu2b\\requirements.txt C:\\Users\\mouni\\AppData\\Local\\Temp\\pip_resolve_gpapqu2b\\requirements.in\n",
      "    pip-compile timed out\n",
      "  Conflict persists. Involved: {'pandas', 'tensorflow', 'some-ml-tool'}. Sub-dep: None\n",
      "    [Neighbors] Current node reqs: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "    [Neighbors] Packages targeted for modification based on conflict: {'pandas', 'tensorflow', 'some-ml-tool'}\n",
      "      [Neighbors] Considering modifications for 'pandas' (current: ==1.4.4)\n",
      "        [Neighbors] Versions to try for 'pandas': []\n",
      "      [Neighbors] Considering modifications for 'some-ml-tool' (current: ==1.0)\n",
      "        [Neighbors] Versions to try for 'some-ml-tool': []\n",
      "      [Neighbors] Considering modifications for 'tensorflow' (current: ==2.3.0)\n",
      "        [Neighbors] Versions to try for 'tensorflow': ['2.13.0', '2.10.0', '2.9.0', '2.6.0', '2.5.0']...\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.3.0' to '==2.13.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.3.0' to '==2.10.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.3.0' to '==2.9.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.3.0' to '==2.6.0', cost=2.00\n",
      "          [Neighbors] Generated: Changed tensorflow from '==2.3.0' to '==2.5.0', cost=2.00\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.13.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.9.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "    Skipping neighbor (already processed better): pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.5.0\n",
      "\n",
      "--- Iteration 12/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.5.0' to '==2.3.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.3.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 13/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.13.0' to '==2.10.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.10.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      "--- Iteration 14/15 ---\n",
      "  Expanding node: f=7.00 (g=4.00, h=3.00)\n",
      "  Action leading to this node: 'Changed tensorflow from '==2.9.0' to '==2.6.0''\n",
      "  Node requirements: pandas==1.4.4, some-ml-tool==1.0, tensorflow==2.6.0\n",
      "  (Skipping: already processed this state via an equal or better path)\n",
      "\n",
      ">>> FAILURE: No solution found after 14 iterations (max: 15). <<<\n",
      "  Open set is empty.\n",
      "\n",
      "--- No Solution Found (Manual Test) ---\n",
      "\n",
      "Total time for Manual Test: 1260.234 seconds\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Optional, Set, FrozenSet, Any\n",
    "from dataclasses import dataclass, field\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "import json # For potential caching or structured errors later\n",
    "import sys\n",
    "# --- Packaging Library (Optional but Recommended) ---\n",
    "try:\n",
    "    from packaging.specifiers import SpecifierSet, InvalidSpecifier\n",
    "    from packaging.version import Version, InvalidVersion\n",
    "    PACKAGING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PACKAGING_AVAILABLE = False\n",
    "    print(\"CRITICAL WARNING: 'packaging' library not found. Install with: pip install packaging\")\n",
    "    print(\"                 Version comparison and specifier validation will be limited.\")\n",
    "    # Dummy classes if 'packaging' is not available\n",
    "    class Version:\n",
    "        def __init__(self, v_str):\n",
    "            self.v_str = str(v_str)\n",
    "            try: # Basic major.minor.micro parsing\n",
    "                parts = [int(p) for p in self.v_str.split('.')[:3]]\n",
    "                self.major = parts[0] if len(parts) > 0 else 0\n",
    "                self.minor = parts[1] if len(parts) > 1 else 0\n",
    "                self.micro = parts[2] if len(parts) > 2 else 0\n",
    "            except ValueError:\n",
    "                self.major, self.minor, self.micro = 0, 0, 0\n",
    "            self.public = self.v_str # Simplified\n",
    "\n",
    "        def __str__(self): return self.v_str\n",
    "        def __lt__(self, other): return self.v_str < other.v_str # Naive string comparison\n",
    "        def __eq__(self, other): return self.v_str == other.v_str\n",
    "        def __hash__(self): return hash(self.v_str)\n",
    "\n",
    "    class SpecifierSet:\n",
    "        def __init__(self, s_str=\"\"): self.s_str = str(s_str) if s_str else \"\"\n",
    "        def __contains__(self, version_obj: Version) -> bool: # Very naive check\n",
    "            if not self.s_str: return True # Empty specifier matches all\n",
    "            if self.s_str.startswith(\"==\"): return version_obj.v_str == self.s_str[2:]\n",
    "            # Add more naive checks for >=, <=, etc. if necessary for dummy\n",
    "            return True # Overly permissive for dummy\n",
    "        def __str__(self): return self.s_str\n",
    "        def filter(self, versions_iterable): # Dummy filter\n",
    "            return versions_iterable\n",
    "    class InvalidSpecifier(Exception): pass\n",
    "    class InvalidVersion(Exception): pass\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "# Set to True for detailed A* search and pip-compile logs\n",
    "ENABLE_VERBOSE_LOGGING = False\n",
    "\n",
    "def log_verbose(message: str):\n",
    "    if ENABLE_VERBOSE_LOGGING:\n",
    "        print(message)\n",
    "\n",
    "# --- Global Cache for pip-compile results ---\n",
    "PIP_COMPILE_CACHE: Dict[FrozenSet['Requirement'], 'ConflictInfo'] = {}\n",
    "\n",
    "# --- 1. Data Structures ---\n",
    "@dataclass(frozen=True, order=True)\n",
    "class Requirement:\n",
    "    name: str\n",
    "    specifier: str # Can be empty for \"any version\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.name, str) or not self.name:\n",
    "            raise ValueError(\"Requirement name must be a non-empty string.\")\n",
    "        if not isinstance(self.specifier, str):\n",
    "            raise ValueError(\"Requirement specifier must be a string (can be empty).\")\n",
    "        if PACKAGING_AVAILABLE and self.specifier:\n",
    "            try:\n",
    "                SpecifierSet(self.specifier)\n",
    "            except InvalidSpecifier as e:\n",
    "                raise ValueError(f\"Invalid specifier '{self.specifier}' for package '{self.name}': {e}\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}{self.specifier}\" if self.specifier else self.name\n",
    "\n",
    "    def is_exact(self) -> bool:\n",
    "        return self.specifier.startswith(\"==\")\n",
    "\n",
    "    def get_exact_version_str(self) -> Optional[str]:\n",
    "        if self.is_exact() and PACKAGING_AVAILABLE:\n",
    "            try:\n",
    "                return str(Version(self.specifier[2:]).public)\n",
    "            except InvalidVersion:\n",
    "                return None\n",
    "        elif self.is_exact(): # PACKAGING_AVAILABLE is False\n",
    "            return self.specifier[2:]\n",
    "        return None\n",
    "\n",
    "@dataclass\n",
    "class AStarNode:\n",
    "    requirements: FrozenSet[Requirement]\n",
    "    g_score: float = float('inf')\n",
    "    h_score: float = float('inf')\n",
    "    parent: Optional['AStarNode'] = None\n",
    "    last_action: str = \"Initial state\"\n",
    "\n",
    "    @property\n",
    "    def f_score(self) -> float:\n",
    "        return self.g_score + self.h_score\n",
    "\n",
    "    def __lt__(self, other: 'AStarNode'):\n",
    "        if self.f_score != other.f_score:\n",
    "            return self.f_score < other.f_score\n",
    "        if self.g_score != other.g_score:\n",
    "            return self.g_score < other.g_score\n",
    "        return len(self.requirements) < len(other.requirements)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.requirements)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, AStarNode): return False\n",
    "        return self.requirements == other.requirements\n",
    "\n",
    "@dataclass\n",
    "class ConflictInfo:\n",
    "    is_conflict: bool\n",
    "    error_message: str = \"\"\n",
    "    involved_direct_packages: Set[str] = field(default_factory=set)\n",
    "    # (package_name, specifier_hint_from_error)\n",
    "    sub_dependency_culprit: Optional[Tuple[str, str]] = None\n",
    "\n",
    "# --- 2. PyPI Interaction (Simulated) ---\n",
    "SIMULATED_PYPI_VERSIONS: Dict[str, List[str]] = {\n",
    "    \"sphinx\":     [\"4.3.2\", \"5.0.0\", \"5.3.0\", \"6.0.0\", \"6.1.3\", \"6.2.1\"],\n",
    "    \"docutils\":   [\"0.16\", \"0.17\", \"0.17.1\", \"0.18\", \"0.18.1\", \"0.19\", \"0.20\", \"0.20.1\"],\n",
    "    \"requests\":   [\"2.22.0\", \"2.25.1\", \"2.28.1\", \"2.31.0\"],\n",
    "    \"urllib3\":    [\"1.25.11\", \"1.26.5\", \"1.26.15\", \"2.0.0\", \"2.0.7\", \"2.1.0\", \"2.2.0\"],\n",
    "    \"tensorflow\": [\"2.3.0\", \"2.5.0\", \"2.6.0\", \"2.8.0\", \"2.9.0\", \"2.10.0\", \"2.13.0\"], # Added more for TF\n",
    "    \"numpy\":      [\"1.17.0\", \"1.18.5\", \"1.19.5\", \"1.20.3\", \"1.21.6\", \"1.22.0\", \"1.22.4\", \"1.23.5\", \"1.24.0\", \"1.24.4\", \"1.26.0\"], # Added more for numpy\n",
    "    \"flask\":      [\"1.1.0\", \"1.1.4\", \"2.0.0\", \"2.0.3\", \"2.1.0\", \"2.2.0\", \"2.3.0\"],\n",
    "    \"werkzeug\":   [\"0.16.0\", \"1.0.1\", \"2.0.0\", \"2.0.3\", \"2.1.0\", \"2.2.0\", \"2.3.0\"],\n",
    "    \"common-http-util\": [\"1.0\", \"1.4\", \"1.7\", \"2.0\"],\n",
    "    \"elasticsearch\": [\"7.17.0\", \"7.17.9\", \"8.0.0\", \"8.1.0\", \"8.5.0\", \"8.12.0\"], # Added\n",
    "\n",
    "}\n",
    "\n",
    "def get_pypi_versions_to_try(\n",
    "    package_name: str,\n",
    "    current_requirement: Optional[Requirement] = None,\n",
    "    num_around=2, # Number of versions older/newer to current if current is exact\n",
    "    num_latest=3, # Number of latest versions to always consider\n",
    "    num_within_spec=2 # Number of versions to try that satisfy a loose current_requirement spec\n",
    "    ) -> List[str]:\n",
    "\n",
    "    all_versions_str = SIMULATED_PYPI_VERSIONS.get(package_name, [])\n",
    "    if not all_versions_str: return []\n",
    "\n",
    "    if not PACKAGING_AVAILABLE:\n",
    "        return all_versions_str[:num_latest + num_around * 2] # Simplified fallback\n",
    "\n",
    "    try:\n",
    "        all_versions_obj = sorted([Version(v) for v in all_versions_str], reverse=True)\n",
    "    except InvalidVersion:\n",
    "        log_verbose(f\"Warning: Invalid version format in SIMULATED_PYPI_VERSIONS for {package_name}. Using unsorted subset.\")\n",
    "        return all_versions_str[:num_latest + num_around * 2]\n",
    "\n",
    "    versions_to_try_set = set()\n",
    "\n",
    "    # 1. Add a few latest overall versions\n",
    "    for i in range(min(len(all_versions_obj), num_latest)):\n",
    "        versions_to_try_set.add(all_versions_obj[i])\n",
    "\n",
    "    current_version_obj: Optional[Version] = None\n",
    "    current_specifier_set: Optional[SpecifierSet] = None\n",
    "\n",
    "    if current_requirement and current_requirement.specifier:\n",
    "        try:\n",
    "            current_specifier_set = SpecifierSet(current_requirement.specifier)\n",
    "            if current_requirement.is_exact():\n",
    "                current_version_obj = Version(current_requirement.specifier[2:])\n",
    "        except (InvalidSpecifier, InvalidVersion):\n",
    "            pass # Could not parse current specifier or version\n",
    "\n",
    "    # 2. If current requirement has a specifier, try versions within that specifier\n",
    "    if current_specifier_set:\n",
    "        versions_within_spec = sorted(\n",
    "            [v for v in all_versions_obj if v in current_specifier_set],\n",
    "            reverse=True\n",
    "        )\n",
    "        for i in range(min(len(versions_within_spec), num_within_spec)):\n",
    "            versions_to_try_set.add(versions_within_spec[i])\n",
    "        # Also add the absolute latest that satisfies the spec, if not already included\n",
    "        if versions_within_spec:\n",
    "             versions_to_try_set.add(versions_within_spec[0])\n",
    "\n",
    "\n",
    "    # 3. If current version is known (exact), try versions around it\n",
    "    if current_version_obj:\n",
    "        try:\n",
    "            current_idx = all_versions_obj.index(current_version_obj)\n",
    "            # Older\n",
    "            for i in range(1, num_around + 1):\n",
    "                if current_idx + i < len(all_versions_obj):\n",
    "                    versions_to_try_set.add(all_versions_obj[current_idx + i])\n",
    "            # Newer (that are not already latest)\n",
    "            for i in range(1, num_around + 1):\n",
    "                if current_idx - i >= 0:\n",
    "                    versions_to_try_set.add(all_versions_obj[current_idx - i])\n",
    "        except ValueError: # current_version_obj not in all_versions_obj\n",
    "            pass\n",
    "\n",
    "    # Convert to string and sort newest first\n",
    "    return sorted([str(v) for v in versions_to_try_set], key=Version, reverse=True)\n",
    "\n",
    "\n",
    "# --- 3. Real pip-compile Execution and Output Parsing ---\n",
    "def extract_conflict_details_from_error(\n",
    "    stderr: str,\n",
    "    direct_requirements: FrozenSet[Requirement]\n",
    "    ) -> Tuple[Set[str], Optional[Tuple[str, str]]]:\n",
    "\n",
    "    involved_direct_names = set()\n",
    "    sub_dep_culprit: Optional[Tuple[str, str]] = None\n",
    "    direct_req_name_map = {r.name.lower(): r.name for r in direct_requirements}\n",
    "\n",
    "    # More robustly find mentions of direct dependencies\n",
    "    # Look for lines like: \"  foo==1.0 (from user)\" or \"ERROR: ResolutionImpossible: ...\" then list of dependencies\n",
    "    # Or \"  root depends on foo==1.0\"\n",
    "    for req_name_orig_case in direct_req_name_map.values():\n",
    "        # Regex to find the package name, possibly followed by specifiers, in error context\n",
    "        # This pattern tries to catch direct mentions more accurately\n",
    "        if re.search(r\"\\b\" + re.escape(req_name_orig_case) + r\"([<>=!~]=?[\\w.,*-]+)?\\b\", stderr, re.IGNORECASE):\n",
    "            involved_direct_names.add(req_name_orig_case)\n",
    "\n",
    "    # Simpler regex for sub-dependency culprit identification\n",
    "    # Looks for patterns like: \"package_a x.y depends on sub_package_z <1.0\"\n",
    "    # AND \"package_b z.w depends on sub_package_z >=1.0\"\n",
    "    # This is still very basic.\n",
    "    # \"The conflict is caused by:\\n\" followed by lines like \"    somepackage x.y.z depends on conflictingpackage==A\"\n",
    "    conflict_block_match = re.search(r\"The conflict is caused by:(.*?)(\\n\\n|\\Z)\", stderr, re.DOTALL | re.IGNORECASE)\n",
    "    if conflict_block_match:\n",
    "        conflict_text = conflict_block_match.group(1)\n",
    "        dep_lines = re.findall(r\"\\s+([\\w.-]+)\\s+[\\w.-]+\\s+depends on\\s+([\\w.-]+)\\s*([<>=!~]=?[\\w.,*-]*)?\", conflict_text)\n",
    "        potential_culprits = {}\n",
    "        for dependant, dep_name, dep_spec in dep_lines:\n",
    "            if dep_name.lower() not in direct_req_name_map: # If it's a transitive dependency\n",
    "                potential_culprits.setdefault(dep_name, []).append(dep_spec or \"\")\n",
    "\n",
    "        for culprit_name, specs in potential_culprits.items():\n",
    "            if len(specs) > 1 or (len(specs) == 1 and specs[0]): # Multiple conflicting specs for it, or one specific spec\n",
    "                sub_dep_culprit = (culprit_name, \"; \".join(filter(None, specs)))\n",
    "                break # Take the first one\n",
    "\n",
    "    if not involved_direct_names and \"ResolutionImpossible\" in stderr:\n",
    "        # Fallback: if parsing failed to identify specifics but it's a clear resolution error\n",
    "        involved_direct_names = set(direct_req_name_map.values())\n",
    "\n",
    "    return involved_direct_names, sub_dep_culprit\n",
    "\n",
    "\n",
    "def run_real_pip_compile(\n",
    "    requirements_set: FrozenSet[Requirement],\n",
    "    python_executable: str = \"python\",\n",
    "    timeout_seconds: int = 120\n",
    "    ) -> ConflictInfo:\n",
    "\n",
    "    global PIP_COMPILE_CACHE\n",
    "    if requirements_set in PIP_COMPILE_CACHE:\n",
    "        log_verbose(f\"  [Cache] Hit for: {requirements_to_str(requirements_set, 3)}\")\n",
    "        return PIP_COMPILE_CACHE[requirements_set]\n",
    "\n",
    "    log_verbose(f\"  [Resolver] Attempting to resolve: {requirements_to_str(requirements_set, 3)}\")\n",
    "    temp_dir = \"\"\n",
    "    try:\n",
    "        temp_dir = tempfile.mkdtemp(prefix=\"pip_resolve_\")\n",
    "        requirements_in_content = \"\\n\".join(sorted(str(r) for r in requirements_set))\n",
    "        in_file_path = os.path.join(temp_dir, \"requirements.in\")\n",
    "        out_file_path = os.path.join(temp_dir, \"requirements.txt\")\n",
    "\n",
    "        with open(in_file_path, \"w\") as f: f.write(requirements_in_content)\n",
    "\n",
    "        pip_compile_exe = shutil.which(\"pip-compile\") or \"pip-compile\"\n",
    "        # Key change: Add --allow-unsafe. Some packages might be marked unsafe but are fine for resolution testing.\n",
    "        # Add --no-header to simplify output if needed, but verbose is generally good.\n",
    "        cmd = [\n",
    "            pip_compile_exe,\n",
    "            \"--resolver=backtracking\",\n",
    "            \"--verbose\",\n",
    "            \"--output-file\", out_file_path,\n",
    "            # \"--allow-unsafe\", # Consider if needed for certain packages, but can hide real issues.\n",
    "            in_file_path\n",
    "        ]\n",
    "        log_verbose(f\"    Executing: {' '.join(cmd)}\")\n",
    "        process = subprocess.run(cmd, capture_output=True, text=True, shell=False, check=False, timeout=timeout_seconds)\n",
    "\n",
    "        # Combine stdout and stderr for parsing, as pip-compile can log to both\n",
    "        full_output = f\"STDOUT:\\n{process.stdout}\\nSTDERR:\\n{process.stderr}\"\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            # Double-check for error messages even on success, as pip-compile might warn verbosely\n",
    "            if re.search(r\"ERROR:|ResolutionImpossible|Could not find a version\", full_output, re.IGNORECASE):\n",
    "                log_verbose(f\"    pip-compile RC=0 but error pattern found. Output:\\n{full_output[:500]}\")\n",
    "                involved_pkgs, sub_dep = extract_conflict_details_from_error(full_output, requirements_set)\n",
    "                result = ConflictInfo(True, full_output, involved_pkgs, sub_dep)\n",
    "            else:\n",
    "                log_verbose(\"    pip-compile SUCCESS.\")\n",
    "                result = ConflictInfo(is_conflict=False, error_message=\"\")\n",
    "        else:\n",
    "            log_verbose(f\"    pip-compile FAILED (RC={process.returncode}). Output:\\n{full_output[:1000]}\")\n",
    "            involved_pkgs, sub_dep = extract_conflict_details_from_error(full_output, requirements_set)\n",
    "            result = ConflictInfo(True, full_output, involved_pkgs, sub_dep)\n",
    "\n",
    "        PIP_COMPILE_CACHE[requirements_set] = result\n",
    "        return result\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        err_msg = \"pip-compile timed out\"\n",
    "        log_verbose(f\"    {err_msg}\")\n",
    "        result = ConflictInfo(True, err_msg, {r.name for r in requirements_set})\n",
    "        PIP_COMPILE_CACHE[requirements_set] = result\n",
    "        return result\n",
    "    except FileNotFoundError:\n",
    "        msg = f\"CRITICAL: pip-compile command '{pip_compile_exe if 'pip_compile_exe' in locals() else 'pip-compile'}' not found.\"\n",
    "        print(msg)\n",
    "        raise RuntimeError(msg)\n",
    "    except Exception as e:\n",
    "        err_msg = f\"Unexpected pip-compile error: {type(e).__name__}: {e}\"\n",
    "        log_verbose(f\"    {err_msg}\")\n",
    "        # Don't cache unknown general errors as they might be transient\n",
    "        return ConflictInfo(True, err_msg, {r.name for r in requirements_set})\n",
    "    finally:\n",
    "        if temp_dir and os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "\n",
    "# --- 4. A* Algorithm Components ---\n",
    "def parse_requirements_from_str(content: str) -> FrozenSet[Requirement]:\n",
    "    parsed = set()\n",
    "    for line_num, line in enumerate(content.strip().split('\\n'), 1):\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "        # Improved regex supporting comments and various specifier forms\n",
    "        match = re.match(r\"^\\s*([a-zA-Z0-9_.-]+)\\s*((?:[<>=!~]=?|[<>=!~])\\s*[\\w.,*+-]+(?:\\s*,\\s*[<>=!~]=?\\s*[\\w.,*+-]+)*)?\\s*(?:#.*)?$\", line)\n",
    "        if match:\n",
    "            name = match.group(1).strip()\n",
    "            spec = (match.group(2) or \"\").strip()\n",
    "            try:\n",
    "                parsed.add(Requirement(name=name, specifier=spec))\n",
    "            except ValueError as ve: # Catches errors from Requirement.__post_init__\n",
    "                 log_verbose(f\"Warning: Skipping malformed requirement on line {line_num} ('{line}'): {ve}\")\n",
    "        elif line:\n",
    "            log_verbose(f\"Warning: Skipping malformed requirement line {line_num}: '{line}' (no match).\")\n",
    "    return frozenset(parsed)\n",
    "\n",
    "def requirements_to_str(reqs: FrozenSet[Requirement], limit: Optional[int] = None) -> str:\n",
    "    sorted_reqs = sorted(str(r) for r in reqs)\n",
    "    if limit and len(sorted_reqs) > limit:\n",
    "        return \", \".join(sorted_reqs[:limit]) + f\"... (+{len(sorted_reqs) - limit} more)\"\n",
    "    return \", \".join(sorted_reqs)\n",
    "\n",
    "\n",
    "def get_cost_of_action(action_desc: str, req_before: Optional[Requirement], req_after: Requirement) -> float:\n",
    "    base_cost = 1.0\n",
    "\n",
    "    if \"Changed\" in action_desc and req_before is not None:\n",
    "        if not PACKAGING_AVAILABLE:\n",
    "            return base_cost + 0.5 # Generic penalty if cannot compare versions accurately\n",
    "\n",
    "        try:\n",
    "            # Case 1: Both old and new are exact versions\n",
    "            if req_before.is_exact() and req_after.is_exact():\n",
    "                v_before = Version(req_before.specifier[2:])\n",
    "                v_after = Version(req_after.specifier[2:])\n",
    "\n",
    "                if v_before.major != v_after.major: return base_cost + 2.0\n",
    "                if v_before.minor != v_after.minor: return base_cost + 1.0\n",
    "                if v_before.micro != v_after.micro: return base_cost + 0.5\n",
    "                return base_cost + 0.25 # Smaller changes (epoch, pre/post release)\n",
    "            # Case 2: Changing from a non-exact to an exact specifier\n",
    "            elif not req_before.is_exact() and req_after.is_exact():\n",
    "                # If the new exact version satisfies the old loose specifier, it's a low-cost \"pinning\"\n",
    "                old_spec_set = SpecifierSet(req_before.specifier)\n",
    "                new_version = Version(req_after.specifier[2:])\n",
    "                if new_version in old_spec_set:\n",
    "                    return base_cost + 0.1 # Very low cost for pinning within allowed range\n",
    "                else:\n",
    "                    return base_cost + 1.7 # Pinning to something outside original loose spec\n",
    "            # Case 3: Other changes (e.g. exact to non-exact, non-exact to different non-exact)\n",
    "            else:\n",
    "                return base_cost + 1.5\n",
    "        except (InvalidVersion, InvalidSpecifier, TypeError, AttributeError):\n",
    "            return base_cost + 1.2 # Fallback if version/specifier parsing fails\n",
    "    # TODO: Define costs for other actions (loosening, pinning transitive, removing)\n",
    "    return base_cost\n",
    "\n",
    "def heuristic_estimate_to_goal(\n",
    "    _current_requirements: FrozenSet[Requirement],\n",
    "    conflict_info: ConflictInfo,\n",
    "    _original_direct_reqs: FrozenSet[Requirement]\n",
    "    ) -> float:\n",
    "    if not conflict_info.is_conflict:\n",
    "        return 0.0\n",
    "\n",
    "    num_involved = len(conflict_info.involved_direct_packages)\n",
    "    # Slightly higher heuristic if a specific sub-dependency is identified as a multi-package problem\n",
    "    if conflict_info.sub_dependency_culprit and num_involved > 1:\n",
    "        return float(num_involved) + 0.5\n",
    "    # Base heuristic: number of direct dependencies involved, or 1 if unknown but conflict exists\n",
    "    return float(num_involved) if num_involved > 0 else 1.0\n",
    "\n",
    "\n",
    "def get_neighbors(\n",
    "    current_node: AStarNode,\n",
    "    original_direct_reqs: FrozenSet[Requirement],\n",
    "    conflict_info_for_guidance: ConflictInfo\n",
    "    ) -> List[Tuple[FrozenSet[Requirement], str, float]]:\n",
    "\n",
    "    neighbors: List[Tuple[FrozenSet[Requirement], str, float]] = []\n",
    "    current_reqs_map = {r.name: r for r in current_node.requirements}\n",
    "\n",
    "    pkgs_to_modify_names = conflict_info_for_guidance.involved_direct_packages\n",
    "    if not pkgs_to_modify_names and conflict_info_for_guidance.is_conflict:\n",
    "        pkgs_to_modify_names = {r.name for r in original_direct_reqs}\n",
    "        log_verbose(\"    [Neighbors] Fallback: targeting all original direct dependencies.\")\n",
    "\n",
    "    log_verbose(f\"    [Neighbors] Current node reqs: {requirements_to_str(current_node.requirements, 5)}\")\n",
    "    log_verbose(f\"    [Neighbors] Packages targeted for modification based on conflict: {pkgs_to_modify_names or 'None (no conflict or no specifics)'}\")\n",
    "\n",
    "    for orig_req_template in original_direct_reqs:\n",
    "        package_name_to_modify = orig_req_template.name\n",
    "        if package_name_to_modify not in pkgs_to_modify_names:\n",
    "            continue\n",
    "\n",
    "        current_req_obj = current_reqs_map.get(package_name_to_modify)\n",
    "        if not current_req_obj: # Should ideally not happen\n",
    "            log_verbose(f\"    [Neighbors] Warning: Original package '{package_name_to_modify}' not found in current node's requirements. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        log_verbose(f\"      [Neighbors] Considering modifications for '{package_name_to_modify}' (current: {current_req_obj.specifier})\")\n",
    "        # Pass current_req_obj to get_pypi_versions_to_try for more context\n",
    "        versions_to_try = get_pypi_versions_to_try(package_name_to_modify, current_req_obj)\n",
    "        log_verbose(f\"        [Neighbors] Versions to try for '{package_name_to_modify}': {versions_to_try[:5]}{'...' if len(versions_to_try)>5 else ''}\")\n",
    "\n",
    "\n",
    "        for v_str_to_try in versions_to_try:\n",
    "            new_spec = f\"=={v_str_to_try}\" # Primary action: change to an exact version\n",
    "            if new_spec == current_req_obj.specifier:\n",
    "                continue\n",
    "\n",
    "            new_req_for_pkg = Requirement(name=package_name_to_modify, specifier=new_spec)\n",
    "            \n",
    "            # Construct the new set of requirements by replacing the old one\n",
    "            temp_new_reqs_list = [r for r in current_node.requirements if r.name != package_name_to_modify]\n",
    "            temp_new_reqs_list.append(new_req_for_pkg)\n",
    "            new_requirements_set = frozenset(temp_new_reqs_list)\n",
    "\n",
    "            action_desc = f\"Changed {package_name_to_modify} from '{current_req_obj.specifier}' to '{new_spec}'\"\n",
    "            action_cost = get_cost_of_action(action_desc, current_req_obj, new_req_for_pkg)\n",
    "            neighbors.append((new_requirements_set, action_desc, action_cost))\n",
    "            log_verbose(f\"          [Neighbors] Generated: {action_desc}, cost={action_cost:.2f}\")\n",
    "\n",
    "    # TODO: Implement other neighbor generation strategies:\n",
    "    # 1. Loosen constraint (e.g., from ==1.2.3 to ~=1.2)\n",
    "    #    - Action: \"Loosened {pkg} from {old_spec} to {new_loose_spec}\"\n",
    "    #    - Cost: Higher than exact change, lower than major version jump.\n",
    "    # 2. Pin problematic transitive dependency (if sub_dependency_culprit is identified)\n",
    "    #    - Action: \"Pinned transitive {sub_dep_name} to {version_from_error_or_pypi}\"\n",
    "    #    - Cost: Relatively high.\n",
    "    #    - This adds a new Requirement to the set.\n",
    "    # 3. Remove a direct dependency (as a last resort)\n",
    "    #    - Action: \"Removed direct {pkg}\"\n",
    "    #    - Cost: Very high.\n",
    "\n",
    "    if not neighbors and conflict_info_for_guidance.is_conflict:\n",
    "        log_verbose(f\"    [Neighbors] WARNING: No neighbors generated for conflicting node with reqs: {requirements_to_str(current_node.requirements, 3)}\")\n",
    "    return neighbors\n",
    "\n",
    "def reconstruct_path(node: AStarNode) -> List[Tuple[str, FrozenSet[Requirement]]]:\n",
    "    path = []\n",
    "    current = node\n",
    "    while current:\n",
    "        path.append((current.last_action, current.requirements))\n",
    "        current = current.parent\n",
    "    return path[::-1]\n",
    "\n",
    "# --- 5. A* Solver Function ---\n",
    "def solve_dependencies_astar(\n",
    "    initial_requirements_str: str,\n",
    "    max_iterations=50, # Increased default max_iterations\n",
    "    python_executable=\"python\"\n",
    "    ) -> Optional[Tuple[FrozenSet[Requirement], List[Tuple[str, FrozenSet[Requirement]]]]]:\n",
    "\n",
    "    log_verbose(\"Parsing initial requirements...\")\n",
    "    original_direct_reqs = parse_requirements_from_str(initial_requirements_str)\n",
    "    if not original_direct_reqs:\n",
    "        print(\"ERROR: No valid requirements parsed from initial input.\")\n",
    "        return None\n",
    "    log_verbose(f\"Initial direct requirements: {requirements_to_str(original_direct_reqs)}\")\n",
    "\n",
    "    log_verbose(\"Performing initial pip-compile run for start_node...\")\n",
    "    initial_conflict_info = run_real_pip_compile(original_direct_reqs, python_executable)\n",
    "    initial_h_score = heuristic_estimate_to_goal(original_direct_reqs, initial_conflict_info, original_direct_reqs)\n",
    "\n",
    "    start_node = AStarNode(\n",
    "        requirements=original_direct_reqs,\n",
    "        g_score=0,\n",
    "        h_score=initial_h_score\n",
    "    )\n",
    "\n",
    "    open_set_pq: List[AStarNode] = [start_node]\n",
    "    processed_node_g_scores: Dict[FrozenSet[Requirement], float] = {}\n",
    "\n",
    "    print(f\"Starting A* search. Max iterations: {max_iterations}. Python: {python_executable}\")\n",
    "    log_verbose(f\"Initial node: f={start_node.f_score:.2f} (g=0, h={initial_h_score:.2f}), reqs: {requirements_to_str(start_node.requirements, 3)}\")\n",
    "    if initial_conflict_info.is_conflict:\n",
    "        log_verbose(f\"  Initial conflict involves: {initial_conflict_info.involved_direct_packages or 'unknown'}\")\n",
    "        if initial_conflict_info.sub_dependency_culprit:\n",
    "            log_verbose(f\"  Sub-dependency hint: {initial_conflict_info.sub_dependency_culprit}\")\n",
    "\n",
    "    iteration_count = 0\n",
    "    while open_set_pq and iteration_count < max_iterations:\n",
    "        iteration_count += 1\n",
    "        current_node = heapq.heappop(open_set_pq)\n",
    "\n",
    "        log_verbose(f\"\\n--- Iteration {iteration_count}/{max_iterations} ---\")\n",
    "        log_verbose(f\"  Expanding node: f={current_node.f_score:.2f} (g={current_node.g_score:.2f}, h={current_node.h_score:.2f})\")\n",
    "        log_verbose(f\"  Action leading to this node: '{current_node.last_action}'\")\n",
    "        log_verbose(f\"  Node requirements: {requirements_to_str(current_node.requirements, 5)}\")\n",
    "\n",
    "        if current_node.requirements in processed_node_g_scores and \\\n",
    "           current_node.g_score >= processed_node_g_scores[current_node.requirements]:\n",
    "            log_verbose(\"  (Skipping: already processed this state via an equal or better path)\")\n",
    "            continue\n",
    "        processed_node_g_scores[current_node.requirements] = current_node.g_score\n",
    "\n",
    "        # Actual GOAL TEST\n",
    "        current_node_conflict_info = run_real_pip_compile(current_node.requirements, python_executable)\n",
    "\n",
    "        if not current_node_conflict_info.is_conflict:\n",
    "            print(f\"\\n>>> SUCCESS: Solution Found after {iteration_count} iterations! <<<\")\n",
    "            solution_path = reconstruct_path(current_node)\n",
    "            return current_node.requirements, solution_path\n",
    "\n",
    "        log_verbose(f\"  Conflict persists. Involved: {current_node_conflict_info.involved_direct_packages or 'unknown'}. Sub-dep: {current_node_conflict_info.sub_dependency_culprit}\")\n",
    "\n",
    "        # Generate neighbors\n",
    "        for neighbor_reqs_set, action_desc, action_cost in get_neighbors(current_node, original_direct_reqs, current_node_conflict_info):\n",
    "            tentative_g_score = current_node.g_score + action_cost\n",
    "\n",
    "            if neighbor_reqs_set in processed_node_g_scores and \\\n",
    "               tentative_g_score >= processed_node_g_scores[neighbor_reqs_set]:\n",
    "                log_verbose(f\"    Skipping neighbor (already processed better): {requirements_to_str(neighbor_reqs_set,3)}\")\n",
    "                continue\n",
    "\n",
    "            # Heuristic for neighbor based on parent's (current_node's) conflict info\n",
    "            neighbor_h_score = heuristic_estimate_to_goal(neighbor_reqs_set, current_node_conflict_info, original_direct_reqs)\n",
    "            neighbor_node = AStarNode(\n",
    "                requirements=neighbor_reqs_set,\n",
    "                g_score=tentative_g_score,\n",
    "                h_score=neighbor_h_score,\n",
    "                parent=current_node,\n",
    "                last_action=action_desc\n",
    "            )\n",
    "            heapq.heappush(open_set_pq, neighbor_node)\n",
    "            log_verbose(f\"    Added neighbor to OPEN: f={neighbor_node.f_score:.2f}, g={neighbor_node.g_score:.2f}, h={neighbor_node.h_score:.2f} | Action: '{action_desc}' | Reqs: {requirements_to_str(neighbor_node.requirements,3)}\")\n",
    "\n",
    "    print(f\"\\n>>> FAILURE: No solution found after {iteration_count} iterations (max: {max_iterations}). <<<\")\n",
    "    if open_set_pq:\n",
    "        log_verbose(f\"  Open set still has {len(open_set_pq)} nodes. Lowest f_score: {open_set_pq[0].f_score:.2f}\")\n",
    "    else:\n",
    "        log_verbose(\"  Open set is empty.\")\n",
    "    return None\n",
    "\n",
    "# --- 6. Test Case Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    current_python_interpreter = sys.executable\n",
    "    print(f\"Script (Optimized V3) is running under Python interpreter: {current_python_interpreter}\")\n",
    "\n",
    "    pip_compile_exe_path_check = shutil.which(\"pip-compile\")\n",
    "    try:\n",
    "        cmd_version = [pip_compile_exe_path_check or \"pip-compile\", \"--version\"]\n",
    "        use_shell_ver_check = (pip_compile_exe_path_check is None)\n",
    "        pip_tools_check_run = subprocess.run(cmd_version, shell=use_shell_ver_check, check=True, capture_output=True, text=True, timeout=10)\n",
    "        print(f\"pip-compile command found. Version: { (pip_tools_check_run.stdout.strip() or pip_tools_check_run.stderr.strip()) }\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: 'pip-compile' command failed or not found. Error: {e}\")\n",
    "        print(\"Ensure 'pip-tools' is installed and 'pip-compile' is in your system PATH.\")\n",
    "        if input(\"Continue without pip-compile check? (y/N): \").lower() != 'y':\n",
    "            sys.exit(1)\n",
    "\n",
    "    if not PACKAGING_AVAILABLE:\n",
    "        print(\"Reminder: 'packaging' library not found. Functionality will be limited.\")\n",
    "\n",
    "    # Test Cases\n",
    "    test_cases = {\n",
    "        \" Sphinx and Docutils Compatibility\": \"\"\"\n",
    "requests==2.25.1\n",
    "urllib3==2.0.0\n",
    "\"\"\",    # Expected: requests==2.25.1, urllib3==1.26.15 OR requests==2.31.0, urllib3==2.0.0\n",
    "    }\n",
    "\n",
    "    # Toggle verbose logging for testing\n",
    "    # ENABLE_VERBOSE_LOGGING = True # Uncomment this line to get detailed logs\n",
    "\n",
    "    for test_name, initial_reqs_content in test_cases.items():\n",
    "        print(f\"\\n\\n===== Running Test Case: {test_name} =====\")\n",
    "        print(f\"Initial requirements:\\n{initial_reqs_content.strip()}\\n\")\n",
    "\n",
    "        PIP_COMPILE_CACHE.clear()\n",
    "        start_time = time.time()\n",
    "        result_tuple = solve_dependencies_astar(\n",
    "            initial_reqs_content,\n",
    "            python_executable=current_python_interpreter,\n",
    "            max_iterations=30 # Can be adjusted per test if needed\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        if result_tuple:\n",
    "            final_requirements, path = result_tuple\n",
    "            print(\"\\n--- Final Solution Found ---\")\n",
    "            print(\"Solved Requirements:\")\n",
    "            for req_obj in sorted(list(final_requirements), key=lambda r: r.name):\n",
    "                print(f\"  {req_obj}\")\n",
    "            print(\"\\nPath to solution (Actions taken):\")\n",
    "            for i, (action, req_set_in_path) in enumerate(path):\n",
    "                print(f\"  Step {i}: {action} -> Reqs: {requirements_to_str(req_set_in_path, 3)}\")\n",
    "        else:\n",
    "            print(\"\\n--- No Solution Found for this test case ---\")\n",
    "\n",
    "        print(f\"\\nTotal time for {test_name}: {end_time - start_time:.3f} seconds\")\n",
    "        print(f\"Cache size for {test_name}: {len(PIP_COMPILE_CACHE)} entries.\")\n",
    "        print(\"=========================================\")\n",
    "\n",
    "    # Manual test for the problematic case to observe behavior\n",
    "    print(\"\\n\\n===== Running Manual Debug Test Case =====\")\n",
    "    manual_test_reqs = \"\"\"\n",
    "tensorflow==2.8.0\n",
    "pandas==1.4.4\n",
    "some-ml-tool==1.0 \n",
    "\"\"\"\n",
    "    print(f\"Initial requirements:\\n{manual_test_reqs.strip()}\\n\")\n",
    "    PIP_COMPILE_CACHE.clear()\n",
    "    ENABLE_VERBOSE_LOGGING = True # Force verbose for this one\n",
    "    start_time = time.time()\n",
    "    result_tuple = solve_dependencies_astar(\n",
    "        manual_test_reqs,\n",
    "        python_executable=current_python_interpreter,\n",
    "        max_iterations=15 # Lower iterations for quicker observation if it gets stuck\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    ENABLE_VERBOSE_LOGGING = False # Reset\n",
    "\n",
    "    if result_tuple:\n",
    "        final_requirements, path = result_tuple\n",
    "        print(\"\\n--- Final Solution Found (Manual Test) ---\")\n",
    "        print(\"Solved Requirements:\")\n",
    "        for req_obj in sorted(list(final_requirements), key=lambda r: r.name): print(f\"  {req_obj}\")\n",
    "    else:\n",
    "        print(\"\\n--- No Solution Found (Manual Test) ---\")\n",
    "    print(f\"\\nTotal time for Manual Test: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b743fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6848866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python interpreter: c:\\Users\\mouni\\anaconda3\\python.exe\n",
      "\n",
      "\n",
      "==================== Running Test Case: Happy Path (No Conflict) ====================\n",
      "Initial requirements:\n",
      "requests==2.31.0\n",
      "flask==2.3.0\n",
      "\n",
      "Agent Initialized: LLM 'deepseek/deepseek-chat' is configured.\n",
      "Starting Agentic A* search for: flask==2.3.0, requests==2.31.0\n",
      "  [Resolver] Attempting to resolve: flask==2.3.0, requests==2.31.0\n",
      "\n",
      "--- Iteration 1/20 | f=0.00 (g=0.00, h=0.00) ---\n",
      "  Expanding on action: 'Initial state'\n",
      "  [Cache] Hit for: flask==2.3.0, requests==2.31.0\n",
      "\n",
      ">>> SUCCESS: Solution Found after 1 iterations! <<<\n",
      "\n",
      "--- Final Solution Found ---\n",
      "Solved Requirements:\n",
      "  flask==2.3.0\n",
      "  requests==2.31.0\n",
      "\n",
      "Path to solution (Actions taken):\n",
      "\n",
      "Time: 6.91s | pip-compile calls: 1 | LLM calls: 0\n",
      "==================================================================\n",
      "\n",
      "\n",
      "==================== Running Test Case: Simple Direct Conflict ====================\n",
      "Initial requirements:\n",
      "sphinx==4.3.2\n",
      "docutils==0.20.1\n",
      "\n",
      "Agent Initialized: LLM 'deepseek/deepseek-chat' is configured.\n",
      "Starting Agentic A* search for: docutils==0.20.1, sphinx==4.3.2\n",
      "  [Resolver] Attempting to resolve: docutils==0.20.1, sphinx==4.3.2\n",
      "Initial check failed with UNKNOWN.\n",
      "  [Agent] LLM analysis cache MISS for ErrorType.UNKNOWN. Querying LLM...\n",
      "  [Agent] LLM analysis received: The conflict arises because sphinx 4.3.2 requires docutils<0.18, while docutils==0.20.1 is explicitly requested.\n",
      "\n",
      "--- Iteration 1/20 | f=2.00 (g=0.00, h=2.00) ---\n",
      "  Expanding on action: 'Initial state'\n",
      "  [Cache] Hit for: docutils==0.20.1, sphinx==4.3.2\n",
      "  Conflict persists (UNKNOWN). Analyzing with agent...\n",
      "  [Agent] LLM analysis cache HIT.\n",
      "    [Neighbors] Generating neighbors from agent's suggestions...\n",
      "    [Neighbors] Fallback: targeting {'sphinx', 'docutils'} for version changes.\n",
      "    Added neighbor to OPEN: f=3.00 | Action: 'LLM:CHANGE_VERSION: to docutils==0.17.1'\n",
      "    Added neighbor to OPEN: f=4.00 | Action: 'Fallback:Change sphinx to ==7.0.0'\n",
      "    Added neighbor to OPEN: f=4.00 | Action: 'Fallback:Change docutils to ==0.18.1'\n",
      "\n",
      "--- Iteration 2/20 | f=3.00 (g=1.00, h=2.00) ---\n",
      "  Expanding on action: 'LLM:CHANGE_VERSION: to docutils==0.17.1'\n",
      "  [Resolver] Attempting to resolve: docutils==0.17.1, sphinx==4.3.2\n",
      "\n",
      ">>> SUCCESS: Solution Found after 2 iterations! <<<\n",
      "\n",
      "--- Final Solution Found ---\n",
      "Solved Requirements:\n",
      "  docutils==0.17.1\n",
      "  sphinx==4.3.2\n",
      "\n",
      "Path to solution (Actions taken):\n",
      "  Step 1: LLM:CHANGE_VERSION: to docutils==0.17.1\n",
      "\n",
      "Time: 17.04s | pip-compile calls: 2 | LLM calls: 1\n",
      "================================================================\n",
      "\n",
      "\n",
      "==================== Running Test Case: Medium: Diamond Dependency ====================\n",
      "Initial requirements:\n",
      "requests==2.25.1\n",
      "elasticsearch==8.5.0\n",
      "\n",
      "Agent Initialized: LLM 'deepseek/deepseek-chat' is configured.\n",
      "Starting Agentic A* search for: elasticsearch==8.5.0, requests==2.25.1\n",
      "  [Resolver] Attempting to resolve: elasticsearch==8.5.0, requests==2.25.1\n",
      "\n",
      "--- Iteration 1/20 | f=0.00 (g=0.00, h=0.00) ---\n",
      "  Expanding on action: 'Initial state'\n",
      "  [Cache] Hit for: elasticsearch==8.5.0, requests==2.25.1\n",
      "\n",
      ">>> SUCCESS: Solution Found after 1 iterations! <<<\n",
      "\n",
      "--- Final Solution Found ---\n",
      "Solved Requirements:\n",
      "  elasticsearch==8.5.0\n",
      "  requests==2.25.1\n",
      "\n",
      "Path to solution (Actions taken):\n",
      "\n",
      "Time: 5.21s | pip-compile calls: 1 | LLM calls: 0\n",
      "====================================================================\n",
      "\n",
      "\n",
      "==================== Running Test Case: Difficult: The Great NumPy War ====================\n",
      "Initial requirements:\n",
      "flask==1.1.4\n",
      "werkzeug==2.3.0\n",
      "\n",
      "Agent Initialized: LLM 'deepseek/deepseek-chat' is configured.\n",
      "Starting Agentic A* search for: flask==1.1.4, werkzeug==2.3.0\n",
      "  [Resolver] Attempting to resolve: flask==1.1.4, werkzeug==2.3.0\n",
      "Initial check failed with UNKNOWN.\n",
      "  [Agent] LLM analysis cache MISS for ErrorType.UNKNOWN. Querying LLM...\n",
      "  [Agent] LLM analysis received: The conflict arises because Flask 1.1.4 requires Werkzeug<2.0, but the user explicitly requested Werkzeug==2.3.0.\n",
      "\n",
      "--- Iteration 1/20 | f=2.00 (g=0.00, h=2.00) ---\n",
      "  Expanding on action: 'Initial state'\n",
      "  [Cache] Hit for: flask==1.1.4, werkzeug==2.3.0\n",
      "  Conflict persists (UNKNOWN). Analyzing with agent...\n",
      "  [Agent] LLM analysis cache HIT.\n",
      "    [Neighbors] Generating neighbors from agent's suggestions...\n",
      "    [Neighbors] Fallback: targeting {'werkzeug', 'flask'} for version changes.\n",
      "    Added neighbor to OPEN: f=3.50 | Action: 'LLM:COMBO: flask and werkzeug'\n",
      "    Added neighbor to OPEN: f=4.00 | Action: 'Fallback:Change werkzeug to ==2.2.0'\n",
      "    Added neighbor to OPEN: f=4.00 | Action: 'Fallback:Change flask to ==2.3.0'\n",
      "\n",
      "--- Iteration 2/20 | f=3.50 (g=1.50, h=2.00) ---\n",
      "  Expanding on action: 'LLM:COMBO: flask and werkzeug'\n",
      "  [Resolver] Attempting to resolve: flask>=2.0.0, werkzeug>=0.15,<2.0\n",
      "  Conflict persists (UNKNOWN). Analyzing with agent...\n",
      "  [Agent] LLM analysis cache MISS for ErrorType.UNKNOWN. Querying LLM...\n",
      "  [Agent] LLM analysis received: The conflict arises because Flask versions >=2.0.0 require Werkzeug>=2.0, but the user has specified Werkzeug<2.0.\n",
      "    [Neighbors] Generating neighbors from agent's suggestions...\n",
      "    [Neighbors] Fallback: targeting {'werkzeug', 'flask'} for version changes.\n",
      "    Added neighbor to OPEN: f=5.00 | Action: 'LLM:COMBO: flask and werkzeug'\n",
      "    Added neighbor to OPEN: f=5.00 | Action: 'LLM:COMBO: flask and werkzeug'\n",
      "    Added neighbor to OPEN: f=5.50 | Action: 'Fallback:Change werkzeug to ==2.3.0'\n",
      "    Added neighbor to OPEN: f=5.50 | Action: 'Fallback:Change flask to ==2.3.0'\n",
      "\n",
      "--- Iteration 3/20 | f=4.00 (g=2.00, h=2.00) ---\n",
      "  Expanding on action: 'Fallback:Change werkzeug to ==2.2.0'\n",
      "  [Resolver] Attempting to resolve: flask==1.1.4, werkzeug==2.2.0\n",
      "  Conflict persists (UNKNOWN). Analyzing with agent...\n",
      "  [Agent] LLM analysis cache MISS for ErrorType.UNKNOWN. Querying LLM...\n",
      "  [Agent] LLM analysis received: The conflict arises because flask 1.1.4 requires Werkzeug<2.0, but the user explicitly requested werkzeug==2.2.0.\n",
      "    [Neighbors] Generating neighbors from agent's suggestions...\n",
      "    [Neighbors] Fallback: targeting {'werkzeug', 'flask'} for version changes.\n",
      "    Added neighbor to OPEN: f=5.50 | Action: 'LLM:COMBO: flask and werkzeug'\n",
      "    Added neighbor to OPEN: f=6.00 | Action: 'Fallback:Change flask to ==2.3.0'\n",
      "\n",
      "--- Iteration 4/20 | f=4.00 (g=2.00, h=2.00) ---\n",
      "  Expanding on action: 'Fallback:Change flask to ==2.3.0'\n",
      "  [Resolver] Attempting to resolve: flask==2.3.0, werkzeug==2.3.0\n",
      "\n",
      ">>> SUCCESS: Solution Found after 4 iterations! <<<\n",
      "\n",
      "--- Final Solution Found ---\n",
      "Solved Requirements:\n",
      "  flask==2.3.0\n",
      "  werkzeug==2.3.0\n",
      "\n",
      "Path to solution (Actions taken):\n",
      "  Step 1: Fallback:Change flask to ==2.3.0\n",
      "\n",
      "Time: 62.25s | pip-compile calls: 4 | LLM calls: 3\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Optional, Set, FrozenSet, Any\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# --- Packaging Library (Recommended) ---\n",
    "try:\n",
    "    from packaging.specifiers import SpecifierSet, InvalidSpecifier\n",
    "    from packaging.version import Version, InvalidVersion\n",
    "    PACKAGING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PACKAGING_AVAILABLE = False\n",
    "    # Dummy classes\n",
    "    class Version:\n",
    "        def __init__(self, v_str): self.v_str = str(v_str)\n",
    "        def __str__(self): return self.v_str\n",
    "        def __lt__(self, other): return self.v_str < other.v_str\n",
    "        def __eq__(self, other): return self.v_str == other.v_str\n",
    "        def __hash__(self): return hash(self.v_str)\n",
    "    class SpecifierSet:\n",
    "        def __init__(self, s_str=\"\"): self.s_str = str(s_str)\n",
    "        def __contains__(self, version_obj: Version) -> bool: return True\n",
    "        def __str__(self): return self.s_str\n",
    "        def filter(self, versions_iterable): return versions_iterable\n",
    "    class InvalidSpecifier(Exception): pass\n",
    "    class InvalidVersion(Exception): pass\n",
    "    print(\"CRITICAL WARNING: 'packaging' library not found. Install with: pip install packaging\")\n",
    "\n",
    "# --- Agentic AI Integration ---\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.messages import HumanMessage, SystemMessage\n",
    "    LANGCHAIN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGCHAIN_AVAILABLE = False\n",
    "    print(\"CRITICAL WARNING: 'langchain' libraries not found. AI features disabled. Install with: pip install langchain langchain-openai\")\n",
    "\n",
    "# --- LLM Configuration ---\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"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\")\n",
    "OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "MODEL_NAME = \"deepseek/deepseek-chat\"\n",
    "HTTP_REFERER = os.getenv(\"HTTP_REFERER\", \"http://localhost/dependency-resolver-agent\")\n",
    "APP_TITLE = \"DependencyResolverAgent\"\n",
    "\n",
    "# --- Logging & Caching & Config ---\n",
    "ENABLE_VERBOSE_LOGGING = False\n",
    "PIP_COMPILE_TIMEOUT = 60 # Reduced timeout for faster failure\n",
    "def log_verbose(message: str):\n",
    "    if ENABLE_VERBOSE_LOGGING:\n",
    "        print(message)\n",
    "\n",
    "PIP_COMPILE_CACHE: Dict[FrozenSet['Requirement'], 'ConflictInfo'] = {}\n",
    "LLM_ANALYSIS_CACHE: Dict[str, 'LLMConflictAnalysis'] = {}\n",
    "\n",
    "\n",
    "# --- 1. Enhanced Data Structures ---\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    \"\"\"Categorizes the type of resolution failure.\"\"\"\n",
    "    SUCCESS = \"SUCCESS\"\n",
    "    CONFLICT = \"CONFLICT\"\n",
    "    NOT_FOUND = \"NOT_FOUND\"\n",
    "    TIMEOUT = \"TIMEOUT\"\n",
    "    UNKNOWN = \"UNKNOWN\"\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class Requirement:\n",
    "    name: str\n",
    "    specifier: str = \"\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not isinstance(self.name, str) or not self.name: raise ValueError(\"Req name must be a non-empty string.\")\n",
    "        if not isinstance(self.specifier, str): raise ValueError(\"Req specifier must be a string.\")\n",
    "        if PACKAGING_AVAILABLE and self.specifier:\n",
    "            try: SpecifierSet(self.specifier)\n",
    "            except InvalidSpecifier as e: raise ValueError(f\"Invalid specifier '{self.specifier}' for '{self.name}': {e}\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}{self.specifier}\" if self.specifier else self.name\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LLMAction:\n",
    "    action_type: str\n",
    "    package_name: str\n",
    "    suggested_specifier: Optional[str] = None\n",
    "    reasoning: str = \"\"\n",
    "    # New field for combo actions\n",
    "    actions: List['LLMAction'] = field(default_factory=list)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LLMConflictAnalysis:\n",
    "    reasoning: str\n",
    "    involved_direct_packages: List[str]\n",
    "    suggested_actions: List[LLMAction]\n",
    "\n",
    "@dataclass\n",
    "class ConflictInfo:\n",
    "    error_type: ErrorType\n",
    "    error_message: str = \"\"\n",
    "    analysis: Optional[LLMConflictAnalysis] = None\n",
    "\n",
    "    @property\n",
    "    def is_conflict(self) -> bool:\n",
    "        return self.error_type != ErrorType.SUCCESS\n",
    "\n",
    "@dataclass\n",
    "class AStarNode:\n",
    "    requirements: FrozenSet[Requirement]\n",
    "    g_score: float = float('inf')\n",
    "    h_score: float = float('inf')\n",
    "    parent: Optional['AStarNode'] = None\n",
    "    last_action: str = \"Initial state\"\n",
    "\n",
    "    @property\n",
    "    def f_score(self) -> float: return self.g_score + self.h_score\n",
    "    def __lt__(self, other: 'AStarNode'):\n",
    "        if self.f_score != other.f_score: return self.f_score < other.f_score\n",
    "        return self.g_score < other.g_score\n",
    "    def __hash__(self): return hash(self.requirements)\n",
    "    def __eq__(self, other): return isinstance(other, AStarNode) and self.requirements == other.requirements\n",
    "\n",
    "\n",
    "# --- 2. The AI Agent for Conflict Analysis (Upgraded) ---\n",
    "\n",
    "class DependencyResolutionAgent:\n",
    "    def __init__(self):\n",
    "        if not LANGCHAIN_AVAILABLE or not OPENROUTER_API_KEY.startswith(\"sk-or-v1-\"):\n",
    "            self.llm = None\n",
    "            log_verbose(\"Agent Initialized: LLM is NOT available.\")\n",
    "            return\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=MODEL_NAME, openai_api_key=OPENROUTER_API_KEY, openai_api_base=OPENROUTER_API_BASE,\n",
    "            temperature=0.0, max_tokens=1500, default_headers={\"HTTP-Referer\": HTTP_REFERER, \"X-Title\": APP_TITLE}\n",
    "        )\n",
    "        log_verbose(f\"Agent Initialized: LLM '{MODEL_NAME}' is configured.\")\n",
    "\n",
    "    def analyze_conflict(self, conflict_info: ConflictInfo, current_reqs: FrozenSet[Requirement]) -> LLMConflictAnalysis:\n",
    "        if self.llm is None:\n",
    "            return self._fallback_analysis(current_reqs)\n",
    "\n",
    "        # Cache key includes the error type for more specific caching\n",
    "        cache_key = str(hash((conflict_info.error_type, conflict_info.error_message)))\n",
    "        if cache_key in LLM_ANALYSIS_CACHE:\n",
    "            log_verbose(\"  [Agent] LLM analysis cache HIT.\")\n",
    "            return LLM_ANALYSIS_CACHE[cache_key]\n",
    "\n",
    "        log_verbose(f\"  [Agent] LLM analysis cache MISS for {conflict_info.error_type}. Querying LLM...\")\n",
    "        prompt = self._construct_prompt(conflict_info, current_reqs)\n",
    "        messages = [SystemMessage(content=prompt['system']), HumanMessage(content=prompt['human'])]\n",
    "\n",
    "        try:\n",
    "            response = self.llm.invoke(messages)\n",
    "            analysis = self._parse_llm_response(response.content)\n",
    "            log_verbose(f\"  [Agent] LLM analysis received: {analysis.reasoning}\")\n",
    "            LLM_ANALYSIS_CACHE[cache_key] = analysis\n",
    "            return analysis\n",
    "        except Exception as e:\n",
    "            log_verbose(f\"  [Agent] LLM call failed: {e}. Using fallback analysis.\")\n",
    "            return self._fallback_analysis(current_reqs)\n",
    "\n",
    "    def _construct_prompt(self, conflict_info: ConflictInfo, current_reqs: FrozenSet[Requirement]) -> Dict[str, str]:\n",
    "        # Base prompt with combo action support\n",
    "        system_prompt = \"\"\"\n",
    "You are an expert Python dependency resolver. Your task is to analyze a `pip-compile` error log and provide a structured, actionable solution in a single JSON object.\n",
    "\n",
    "The goal is to find a set of compatible packages. Analyze the conflict and suggest specific, concrete actions.\n",
    "Action types can be: 'CHANGE_VERSION', 'PIN_TRANSITIVE_DEPENDENCY', 'REMOVE_PACKAGE', or 'COMBO'.\n",
    "- 'CHANGE_VERSION': Modify a direct dependency's version.\n",
    "- 'PIN_TRANSITIVE_DEPENDENCY': Add a requirement for a sub-dependency.\n",
    "- 'REMOVE_PACKAGE': Remove a problematic direct dependency (high cost).\n",
    "- 'COMBO': A powerful move that applies multiple actions at once. Use this for complex conflicts requiring coordinated changes.\n",
    "\n",
    "Provide your response as a single JSON object only, with no other text, using the following schema:\n",
    "{\n",
    "  \"reasoning\": \"A brief, one-sentence explanation of the core conflict and your strategy.\",\n",
    "  \"involved_direct_packages\": [\"list\", \"of\", \"direct\", \"dependencies\", \"from the input list that are directly involved\"],\n",
    "  \"suggested_actions\": [\n",
    "    {\n",
    "      \"action_type\": \"COMBO\",\n",
    "      \"package_name\": \"summary of combo action\",\n",
    "      \"suggested_specifier\": null,\n",
    "      \"reasoning\": \"Why this combination of changes is necessary.\",\n",
    "      \"actions\": [\n",
    "          {\"action_type\": \"CHANGE_VERSION\", \"package_name\": \"tensorflow\", \"suggested_specifier\": \"==2.13.0\"},\n",
    "          {\"action_type\": \"PIN_TRANSITIVE_DEPENDENCY\", \"package_name\": \"numpy\", \"suggested_specifier\": \"==1.23.5\"}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"action_type\": \"CHANGE_VERSION\", \"package_name\": \"package-to-change\", \"suggested_specifier\": \"==X.Y.Z\"\n",
    "    }\n",
    "  ]\n",
    "}\"\"\"\n",
    "\n",
    "        # Specialize the prompt based on the error type\n",
    "        error_specific_guidance = \"\"\n",
    "        if conflict_info.error_type == ErrorType.NOT_FOUND:\n",
    "            error_specific_guidance = \"\\n\\nCRITICAL HINT: The error is 'No matching distribution found'. This means the requested package version does not exist for the current environment (e.g., Python version). The ONLY solution is to change the version of the package mentioned in the error. Do not suggest other actions.\"\n",
    "        elif conflict_info.error_type == ErrorType.TIMEOUT:\n",
    "            error_specific_guidance = \"\\n\\nCRITICAL HINT: The previous attempt TIMED OUT. This indicates extreme complexity. Standard version changes are failing. Propose a more drastic, simplifying action. Good options include: 1) A 'COMBO' action to pin a core transitive dependency (like 'numpy' or 'urllib3') while also changing a direct dependency. 2) A larger version jump on a primary package.\"\n",
    "        elif conflict_info.error_type == ErrorType.CONFLICT:\n",
    "            error_specific_guidance = \"\\n\\nCRITICAL HINT: This is a standard dependency conflict. Identify the two packages fighting over a third, and suggest a version change for one of them.\"\n",
    "\n",
    "        human_prompt = f\"\"\"\n",
    "I am trying to resolve the following Python dependencies:\n",
    "{', '.join(sorted(str(r) for r in current_reqs))}\n",
    "\n",
    "I ran `pip-compile` and it failed with a '{conflict_info.error_type.name}' error. Here is the log:\n",
    "--- ERROR LOG ---\n",
    "{conflict_info.error_message}\n",
    "--- END ERROR LOG ---\n",
    "{error_specific_guidance}\n",
    "Provide your JSON analysis.\n",
    "\"\"\"\n",
    "        return {\"system\": system_prompt, \"human\": human_prompt}\n",
    "\n",
    "    def _parse_llm_response(self, response_text: str) -> LLMConflictAnalysis:\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', response_text)\n",
    "            json_str = json_match.group(1) if json_match else response_text\n",
    "            data = json.loads(json_str)\n",
    "            actions = []\n",
    "            for a in data.get('suggested_actions', []):\n",
    "                sub_actions = [LLMAction(**sa) for sa in a.get('actions', [])]\n",
    "                actions.append(LLMAction(\n",
    "                    action_type=a['action_type'], package_name=a['package_name'],\n",
    "                    suggested_specifier=a.get('suggested_specifier'), reasoning=a.get('reasoning', ''),\n",
    "                    actions=sub_actions\n",
    "                ))\n",
    "            return LLMConflictAnalysis(\n",
    "                reasoning=data['reasoning'], involved_direct_packages=data['involved_direct_packages'],\n",
    "                suggested_actions=actions\n",
    "            )\n",
    "        except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "            log_verbose(f\"  [Agent] Failed to parse LLM JSON response: {e}\\nResponse was:\\n{response_text}\")\n",
    "            raise ValueError(\"LLM response parsing failed.\")\n",
    "\n",
    "    def _fallback_analysis(self, direct_reqs: FrozenSet[Requirement]) -> LLMConflictAnalysis:\n",
    "        return LLMConflictAnalysis(\n",
    "            reasoning=\"Fallback analysis: An unknown conflict exists.\",\n",
    "            involved_direct_packages=[r.name for r in direct_reqs], suggested_actions=[]\n",
    "        )\n",
    "\n",
    "\n",
    "# --- 3. PyPI & pip-compile Interaction (Upgraded) ---\n",
    "\n",
    "def get_pypi_versions_to_try(package_name: str, existing_reqs: FrozenSet[Requirement]) -> List[str]:\n",
    "    # A bit smarter: try to avoid versions we know failed.\n",
    "    failed_versions = {r.specifier.replace(\"==\", \"\") for r in existing_reqs if r.name == package_name}\n",
    "    all_versions_str = SIMULATED_PYPI_VERSIONS.get(package_name, [])\n",
    "    if not all_versions_str or not PACKAGING_AVAILABLE: return all_versions_str\n",
    "\n",
    "    valid_versions = [v for v in all_versions_str if v not in failed_versions]\n",
    "    return sorted(valid_versions, key=Version, reverse=True)\n",
    "\n",
    "def run_real_pip_compile(requirements_set: FrozenSet[Requirement], python_executable: str) -> ConflictInfo:\n",
    "    if requirements_set in PIP_COMPILE_CACHE:\n",
    "        log_verbose(f\"  [Cache] Hit for: {requirements_to_str(requirements_set, 3)}\")\n",
    "        return PIP_COMPILE_CACHE[requirements_set]\n",
    "\n",
    "    log_verbose(f\"  [Resolver] Attempting to resolve: {requirements_to_str(requirements_set, 3)}\")\n",
    "    with tempfile.TemporaryDirectory(prefix=\"pip_resolve_\") as temp_dir:\n",
    "        in_file_path = os.path.join(temp_dir, \"requirements.in\")\n",
    "        with open(in_file_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(sorted(str(r) for r in requirements_set)))\n",
    "        try:\n",
    "            cmd = [shutil.which(\"pip-compile\") or \"pip-compile\", \"--resolver=backtracking\", \"--verbose\", in_file_path]\n",
    "            process = subprocess.run(cmd, capture_output=True, text=True, check=False, timeout=PIP_COMPILE_TIMEOUT)\n",
    "\n",
    "            full_output = f\"STDOUT:\\n{process.stdout}\\nSTDERR:\\n{process.stderr}\"\n",
    "            error_type = ErrorType.UNKNOWN\n",
    "            if process.returncode == 0:\n",
    "                error_type = ErrorType.SUCCESS\n",
    "            elif \"No matching distribution found\" in full_output:\n",
    "                error_type = ErrorType.NOT_FOUND\n",
    "            elif \"Requirements conflict\" in full_output:\n",
    "                error_type = ErrorType.CONFLICT\n",
    "            \n",
    "            result = ConflictInfo(error_type=error_type, error_message=full_output)\n",
    "\n",
    "        except subprocess.TimeoutExpired:\n",
    "            result = ConflictInfo(error_type=ErrorType.TIMEOUT, error_message=f\"pip-compile timed out after {PIP_COMPILE_TIMEOUT} seconds.\")\n",
    "        except Exception as e:\n",
    "            result = ConflictInfo(error_type=ErrorType.UNKNOWN, error_message=f\"pip-compile execution failed: {e}\")\n",
    "\n",
    "        PIP_COMPILE_CACHE[requirements_set] = result\n",
    "        return result\n",
    "\n",
    "# --- 4. Enhanced A* Algorithm Components (Upgraded) ---\n",
    "\n",
    "def parse_requirements_from_str(content: str) -> FrozenSet[Requirement]:\n",
    "    # (No changes needed here)\n",
    "    parsed = set()\n",
    "    for line in content.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'): continue\n",
    "        match = re.match(r\"^\\s*([a-zA-Z0-9_.-]+)\\s*((?:[<>=!~]=?|[<>=!~])\\s*[\\w.,*+-]+(?:\\s*,\\s*[<>=!~]=?\\s*[\\w.,*+-]+)*)?\", line)\n",
    "        if match:\n",
    "            try: parsed.add(Requirement(name=match.group(1).strip(), specifier=(match.group(2) or \"\").strip()))\n",
    "            except ValueError as ve: log_verbose(f\"Warning: Skipping malformed requirement '{line}': {ve}\")\n",
    "    return frozenset(parsed)\n",
    "\n",
    "def requirements_to_str(reqs: FrozenSet[Requirement], limit: Optional[int] = None) -> str:\n",
    "    # (No changes needed here)\n",
    "    sorted_reqs = sorted(str(r) for r in reqs)\n",
    "    if limit and len(sorted_reqs) > limit: return \", \".join(sorted_reqs[:limit]) + f\"... (+{len(sorted_reqs) - limit} more)\"\n",
    "    return \", \".join(sorted_reqs)\n",
    "\n",
    "def get_cost_of_action(action_desc: str, error_type: ErrorType) -> float:\n",
    "    \"\"\"Cost is now sensitive to the error type that prompted the action.\"\"\"\n",
    "    base_cost = 1.0\n",
    "    if action_desc.startswith(\"LLM:COMBO\"): base_cost = 1.5 # Powerful move, slightly more expensive\n",
    "    if action_desc.startswith(\"LLM:PIN_TRANSITIVE\"): base_cost = 2.5\n",
    "    if action_desc.startswith(\"LLM:REMOVE_PACKAGE\"): base_cost = 10.0\n",
    "    if action_desc.startswith(\"Fallback:Change\"): base_cost = 2.0 # Higher cost for less certain moves\n",
    "\n",
    "    # Add penalty based on the problem's difficulty\n",
    "    if error_type == ErrorType.TIMEOUT: return base_cost + 5.0\n",
    "    if error_type == ErrorType.NOT_FOUND: return base_cost + 3.0\n",
    "    return base_cost\n",
    "\n",
    "def heuristic_estimate_to_goal(conflict_info: ConflictInfo) -> float:\n",
    "    \"\"\"Heuristic is now much more sensitive to error type.\"\"\"\n",
    "    if not conflict_info.is_conflict: return 0.0\n",
    "\n",
    "    # Penalize difficult error types heavily\n",
    "    if conflict_info.error_type == ErrorType.TIMEOUT: return 10.0\n",
    "    if conflict_info.error_type == ErrorType.NOT_FOUND: return 8.0\n",
    "\n",
    "    analysis = conflict_info.analysis\n",
    "    if analysis:\n",
    "        h = float(len(analysis.involved_direct_packages))\n",
    "        if any(a.action_type == 'PIN_TRANSITIVE_DEPENDENCY' for a in analysis.suggested_actions): h += 1.5\n",
    "        if not analysis.suggested_actions: h += 3.0 # Harder if agent has no ideas\n",
    "        return max(1.0, h)\n",
    "\n",
    "    return 5.0 # High uncertainty default\n",
    "\n",
    "def get_neighbors(current_node: AStarNode, conflict_info: ConflictInfo) -> List[Tuple[FrozenSet[Requirement], str, float]]:\n",
    "    neighbors: List[Tuple[FrozenSet[Requirement], str, float]] = []\n",
    "    current_reqs_map = {r.name: r for r in current_node.requirements}\n",
    "    \n",
    "    # Strategy 1: Act on agent suggestions (now with COMBO support)\n",
    "    if conflict_info.analysis and conflict_info.analysis.suggested_actions:\n",
    "        log_verbose(f\"    [Neighbors] Generating neighbors from agent's suggestions...\")\n",
    "        for action in conflict_info.analysis.suggested_actions:\n",
    "            new_reqs_list = list(current_node.requirements)\n",
    "            action_desc = \"\"\n",
    "\n",
    "            if action.action_type == \"COMBO\" and action.actions:\n",
    "                action_desc = f\"LLM:COMBO: {action.package_name}\"\n",
    "                temp_req_map = {r.name: r for r in new_reqs_list}\n",
    "                for sub_action in action.actions:\n",
    "                    if sub_action.action_type == \"CHANGE_VERSION\":\n",
    "                        temp_req_map[sub_action.package_name] = Requirement(sub_action.package_name, sub_action.suggested_specifier or \"\")\n",
    "                    elif sub_action.action_type == \"PIN_TRANSITIVE_DEPENDENCY\":\n",
    "                        temp_req_map[sub_action.package_name] = Requirement(sub_action.package_name, sub_action.suggested_specifier or \"\")\n",
    "                new_reqs_list = list(temp_req_map.values())\n",
    "\n",
    "            elif action.action_type == \"CHANGE_VERSION\" and action.package_name in current_reqs_map:\n",
    "                new_reqs_list = [r for r in new_reqs_list if r.name != action.package_name]\n",
    "                new_reqs_list.append(Requirement(action.package_name, action.suggested_specifier or \"\"))\n",
    "                action_desc = f\"LLM:CHANGE_VERSION: to {action.package_name}{action.suggested_specifier}\"\n",
    "\n",
    "            elif action.action_type == \"PIN_TRANSITIVE_DEPENDENCY\":\n",
    "                new_reqs_list.append(Requirement(action.package_name, action.suggested_specifier or \"\"))\n",
    "                action_desc = f\"LLM:PIN_TRANSITIVE: Pinned {action.package_name}{action.suggested_specifier}\"\n",
    "            \n",
    "            # (Remove package omitted for brevity, logic is the same)\n",
    "\n",
    "            if action_desc:\n",
    "                cost = get_cost_of_action(action_desc, conflict_info.error_type)\n",
    "                neighbors.append((frozenset(new_reqs_list), action_desc, cost))\n",
    "\n",
    "    # Strategy 2: Smarter Fallback\n",
    "    pkgs_to_modify = set(conflict_info.analysis.involved_direct_packages if conflict_info.analysis else [r.name for r in current_node.requirements])\n",
    "    log_verbose(f\"    [Neighbors] Fallback: targeting {pkgs_to_modify} for version changes.\")\n",
    "    for pkg_name in pkgs_to_modify:\n",
    "        if pkg_name not in current_reqs_map: continue\n",
    "        # Pass current requirements to avoid re-trying failed versions\n",
    "        versions_to_try = get_pypi_versions_to_try(pkg_name, current_node.requirements)\n",
    "        for v_str in versions_to_try[:1]: # Be more conservative with fallback\n",
    "            new_spec = f\"=={v_str}\"\n",
    "            if new_spec == current_reqs_map[pkg_name].specifier: continue\n",
    "            new_req = Requirement(pkg_name, new_spec)\n",
    "            new_reqs_list = [r for r in current_node.requirements if r.name != pkg_name] + [new_req]\n",
    "            action_desc = f\"Fallback:Change {pkg_name} to {new_spec}\"\n",
    "            cost = get_cost_of_action(action_desc, conflict_info.error_type)\n",
    "            neighbors.append((frozenset(new_reqs_list), action_desc, cost))\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def reconstruct_path(node: AStarNode) -> List[Tuple[str, FrozenSet[Requirement]]]:\n",
    "    # (No changes needed here)\n",
    "    path = []\n",
    "    current = node\n",
    "    while current:\n",
    "        path.append((current.last_action, current.requirements))\n",
    "        current = current.parent\n",
    "    return path[::-1]\n",
    "\n",
    "\n",
    "# --- 5. Main A* Solver Function (Upgraded) ---\n",
    "def solve_dependencies_astar(initial_reqs_str: str, max_iterations=20, python_executable=\"python\") -> Optional[Tuple[...]]:\n",
    "    if not LANGCHAIN_AVAILABLE or not OPENROUTER_API_KEY.startswith(\"sk-or-v1-\"):\n",
    "        print(\"\\nERROR: LangChain/API Key not configured. Agentic features are disabled. Aborting.\")\n",
    "        return None\n",
    "\n",
    "    agent = DependencyResolutionAgent()\n",
    "    original_direct_reqs = parse_requirements_from_str(initial_reqs_str)\n",
    "    if not original_direct_reqs: return None\n",
    "\n",
    "    print(f\"Starting Agentic A* search for: {requirements_to_str(original_direct_reqs)}\")\n",
    "\n",
    "    # Initial check\n",
    "    initial_conflict_info = run_real_pip_compile(original_direct_reqs, python_executable)\n",
    "    if initial_conflict_info.is_conflict:\n",
    "        print(f\"Initial check failed with {initial_conflict_info.error_type.name}.\")\n",
    "        initial_conflict_info.analysis = agent.analyze_conflict(initial_conflict_info, original_direct_reqs)\n",
    "    \n",
    "    start_node = AStarNode(\n",
    "        requirements=original_direct_reqs, g_score=0,\n",
    "        h_score=heuristic_estimate_to_goal(initial_conflict_info)\n",
    "    )\n",
    "    open_set_pq, processed_nodes, iteration = [start_node], {}, 0\n",
    "\n",
    "    while open_set_pq and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        current_node = heapq.heappop(open_set_pq)\n",
    "\n",
    "        # More robust check for already processed nodes\n",
    "        if current_node.requirements in processed_nodes and current_node.g_score >= processed_nodes[current_node.requirements]:\n",
    "            log_verbose(f\"  Skipping already processed node: {requirements_to_str(current_node.requirements, 3)}\")\n",
    "            continue\n",
    "        processed_nodes[current_node.requirements] = current_node.g_score\n",
    "\n",
    "        log_verbose(f\"\\n--- Iteration {iteration}/{max_iterations} | f={current_node.f_score:.2f} (g={current_node.g_score:.2f}, h={current_node.h_score:.2f}) ---\")\n",
    "        log_verbose(f\"  Expanding on action: '{current_node.last_action}'\")\n",
    "        \n",
    "        conflict_info = run_real_pip_compile(current_node.requirements, python_executable)\n",
    "        if not conflict_info.is_conflict:\n",
    "            print(f\"\\n>>> SUCCESS: Solution Found after {iteration} iterations! <<<\")\n",
    "            return current_node.requirements, reconstruct_path(current_node)\n",
    "\n",
    "        log_verbose(f\"  Conflict persists ({conflict_info.error_type.name}). Analyzing with agent...\")\n",
    "        conflict_info.analysis = agent.analyze_conflict(conflict_info, current_node.requirements)\n",
    "        \n",
    "        for neighbor_reqs, action_desc, cost in get_neighbors(current_node, conflict_info):\n",
    "            tentative_g_score = current_node.g_score + cost\n",
    "            # Check processed nodes again before adding to open set\n",
    "            if neighbor_reqs in processed_nodes and tentative_g_score >= processed_nodes.get(neighbor_reqs, float('inf')):\n",
    "                 continue\n",
    "\n",
    "            # We need to re-run the heuristic on a *hypothetical* future state.\n",
    "            # For simplicity, we'll base it on the *current* conflict info, as re-running pip-compile is too slow.\n",
    "            # The cost function already incorporates the difficulty.\n",
    "            h_score = heuristic_estimate_to_goal(conflict_info)\n",
    "            neighbor_node = AStarNode(neighbor_reqs, tentative_g_score, h_score, current_node, action_desc)\n",
    "            heapq.heappush(open_set_pq, neighbor_node)\n",
    "            log_verbose(f\"    Added neighbor to OPEN: f={neighbor_node.f_score:.2f} | Action: '{action_desc}'\")\n",
    "\n",
    "    print(f\"\\n>>> FAILURE: No solution found after {iteration} iterations. <<<\")\n",
    "    return None\n",
    "\n",
    "# --- 6. Test Case Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    current_python_interpreter = sys.executable\n",
    "    print(f\"Using Python interpreter: {current_python_interpreter}\")\n",
    "    if not (shutil.which(\"pip-compile\")):\n",
    "        print(\"CRITICAL ERROR: 'pip-compile' not found. Please `pip install pip-tools`.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Add a more difficult test case from our discussion\n",
    "    SIMULATED_PYPI_VERSIONS = {\n",
    "        \"sphinx\": [\"4.3.2\", \"5.3.0\", \"6.1.3\", \"7.0.0\"],\n",
    "        \"docutils\": [\"0.17.1\", \"0.18.1\", \"0.20.1\"],\n",
    "        \"requests\": [\"2.22.0\", \"2.25.1\", \"2.28.1\", \"2.31.0\"], \n",
    "        \"urllib3\": [\"1.25.11\", \"1.26.5\", \"2.0.7\"],\n",
    "        \"flask\": [\"1.1.4\", \"2.0.3\", \"2.2.5\", \"2.3.0\"], \n",
    "        \"werkzeug\": [\"1.0.1\", \"2.0.3\", \"2.2.0\", \"2.3.0\"],\n",
    "        \"elasticsearch\": [\"7.17.9\", \"8.5.0\", \"8.12.0\"],\n",
    "        \"tensorflow\": [\"2.8.0\", \"2.9.0\", \"2.10.0\", \"2.11.0\", \"2.12.0\", \"2.13.0\"], # Note: Real pip will override this\n",
    "        \"pandas\": [\"1.3.5\", \"1.4.4\", \"1.5.3\", \"2.0.0\", \"2.1.0\"],\n",
    "        \"numpy\": [\"1.21.6\", \"1.22.4\", \"1.23.5\", \"1.24.4\", \"1.26.0\"],\n",
    "        \"scikit-learn\": [\"1.0.2\", \"1.1.0\", \"1.2.0\", \"1.3.0\"],\n",
    "    }\n",
    "\n",
    "    all_test_cases = {\n",
    "        \"Happy Path (No Conflict)\": \"requests==2.31.0\\nflask==2.3.0\",\n",
    "        \"Simple Direct Conflict\": \"sphinx==4.3.2\\ndocutils==0.20.1\",\n",
    "        \"Medium: Diamond Dependency\": \"requests==2.25.1\\nelasticsearch==8.5.0\",\n",
    "        \"Difficult: The Great NumPy War\": \"\"\"\n",
    "flask==1.1.4\n",
    "werkzeug==2.3.0\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    ENABLE_VERBOSE_LOGGING = True\n",
    "\n",
    "    for test_name, initial_reqs in all_test_cases.items():\n",
    "        print(f\"\\n\\n{'='*20} Running Test Case: {test_name} {'='*20}\")\n",
    "        print(f\"Initial requirements:\\n{initial_reqs.strip()}\\n\")\n",
    "        # Clear caches for a fresh run\n",
    "        PIP_COMPILE_CACHE.clear()\n",
    "        LLM_ANALYSIS_CACHE.clear()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result_tuple = solve_dependencies_astar(initial_reqs, max_iterations=20, python_executable=current_python_interpreter)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if result_tuple:\n",
    "            final_reqs, path = result_tuple\n",
    "            print(\"\\n--- Final Solution Found ---\")\n",
    "            print(\"Solved Requirements:\\n  \" + \"\\n  \".join(sorted(str(r) for r in final_reqs)))\n",
    "            print(\"\\nPath to solution (Actions taken):\")\n",
    "            for i, (action, _) in enumerate(path[1:], 1): print(f\"  Step {i}: {action}\")\n",
    "        else:\n",
    "            print(\"\\n--- No Solution Found for this test case ---\")\n",
    "        \n",
    "        print(f\"\\nTime: {end_time - start_time:.2f}s | pip-compile calls: {len(PIP_COMPILE_CACHE)} | LLM calls: {len(LLM_ANALYSIS_CACHE)}\")\n",
    "        print(\"=\" * (42 + len(test_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676e0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
